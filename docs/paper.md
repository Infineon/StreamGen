---
title: 'StreamGen: a Python framework for generating streams of labeled data'
tags:
  - Python
  - Data Generation
  - Synthetic Data
  - Data Streams
  - Continual Learning
  - Function Composition
authors:
  - name: Laurenz A. Farthofer
    orcid: 0000-0003-1477-1327
    affiliation: "1, 2" # (Multiple affiliations must be quoted)
affiliations:
  - name: KAI - Kompetenzzentrum Automobil- und Industrieelektronik GmbH, Austria
    index: 1
  - name: Institute of Computer Graphics and Vision, Graz University of Technology, Austria
    index: 2
date: 19 August 2024
bibliography: paper.bib
---

![A tree of sampling functions and transformations as a new data structure and framework for synthetic data generation. Samples are generated by traversing the tree from the root to the leaves. Each path through the tree represents its own class-conditional distribution. The branching points represent categorical distributions which determine the path to take for a sample during the tree traversal. By changing the parameters of the transformations over time, such trees can represent evolving distributions suitable to generate data streams (see \autoref{fig:parameter_schedule}).\label{fig:sampling_tree}](images/sampling_tree.png){ width=95% }

# Summary

StreamGen is a framework for generating streams of labeled, synthetic data from trees composed of sampling functions and transformation monoids (see \autoref{fig:sampling_tree}).

Due to the expensive nature of the labelling process, researchers and machine learning practitioners often rely on existing datasets and stochastic data augmentation pipelines like `torchvision.transforms.Compose` objects [TorchVision @torchvision2016]. While such methods and datasets are appropriate to study learning from static domains, emerging research fields like continual learning study learning on long streams of data, representing evolving experiences. StreamGen addresses this need by giving researchers a tool to model time-dependent, diverse class-conditional distributions.

Such distributions can be represented through the use of a [tree](https://en.wikipedia.org/wiki/Tree_(data_structure)) data structure (or other more general linked structures like directed acyclic graphs) to store sampling functions and transformations. Samples are generated by traversing the tree from the root to the leaves. Each branching point represents a categorical distribution which determines the path to take for a sample during the tree traversal. This information can be utilized for automating the annotation process.

Such a tree comprised of fixed transformations represents a static, class-conditional distribution. In order to extend the framework to evolving distributions (streams), either the **parameters** of the stochastic transformations or the **topology** of the tree needs to be changed over time (see \autoref{fig:parameter_schedule}). Due to the complexity of designing and reasoning about evolving topologies, the first release of StreamGen (version 1.0) focuses on static tree topologies and only schedules the parameters of the transformations and the probabilities of the branching points.

StreamGen implements the following **abstractions** and utility functions to design data streams:

- Classes and functions to construct, schedule and visualize time-dependent parameters
- A selection of custom nodes based on the `NodeMixin` from [anytree](https://github.com/c0fec0de/anytree) [@c0fec0de_anytree_2016]
- A `SamplingTree` class with:
  - A pythonic short-hand construction via nested lists and dictionaries
  - Parameter scheduling and configuration of all nodes via one `update()` call
  - Multiple sampling strategies (stochastic traversal, stratified, pruned)
  - Visualizations using [graphviz](https://www.graphviz.org/) [@gansner_open_1997]
- Stream abstraction to use datasets created with StreamGen in CL frameworks like [avalanche](https://github.com/ContinualAI/avalanche) [@lomonaco_avalanche_2021] or [continuum](https://github.com/Continvvm/continuum) [@douillard_continuum_2021]

The documentation also contains different stream generation examples:

1. Multi-class time series with different data drifts (covariate, prior-probability and concept shift)
2. An analog version of the WM811k dataset [@wu_wafer_2015] (binary images) with covariate shift for Domain Adaptation research
3. A defect density wafer map dataset with geometrically generated patterns

![Changes in the topology of the tree of transformations are one possibility to represent evolving (time-dependent) distributions with different data drift scenarios. \label{fig:parameter_schedule}](images/data_drifts_by_topology_changes.png){ width=100% }

# Statement of need

Most machine learning systems rely on *stationary, labeled, balanced and large-scale* datasets.
**Incremental learning** (IL), also referred to as **lifelong learning** (LL) or **continual learning** (CL), extends the traditional paradigm to dynamic and evolving environments, where learners need to acquire knowledge continually from a stream of experiences (as opposed to learning those concepts jointly from a single dataset) without forgetting concepts from past experiences &mdash; a phenomenon referred to as catastrophic forgetting [@masana_class-incremental_2022].

Existing CL frameworks like [avalanche](https://github.com/ContinualAI/avalanche) [@lomonaco_avalanche_2021] or [continuum](https://github.com/Continvvm/continuum) [@douillard_continuum_2021] construct data streams by *splitting* large classification datasets into multiple *experiences* containing different classes (class-incremental learning), which has a few shortcomings:

- Data streams from real environments are rarely comprised of disjoint experiences
- Such constructed scenarios offer limited insight into factors of the stream other than the class distribution, which are required to study learning scenarios with fewer constraints on the stream properties like domain adaptation or class-incremental scenarios with repetition. Some researchers even argue that the dominance of class-incremental scenarios has lead to the proposal of several rather complex methods, that completely fail in more realistic, unconstrained scenarios with repetition [@cossu_is_2021]
- The evaluation of continual learners on such scenarios is not trivial as evident by the wealth of proposals [@van_de_ven_continual_2024]

To answer different research questions in the field of CL, researchers need knowledge and control over a variety of factors of the underlying data distribution including:

- Class distributions
- Novelties and outliers
- Complexity and evolution of the background domain
- Semantics of the unlabeled parts of a domain
- Class dependencies and composition (for multi-label learning)

A more economical alternative to collecting and labelling streams with desired properties is the **generation** of synthetic streams [@lu_learning_2018].
Some mentionable efforts in that direction include augmentation based dataset generation like [ImageNet-C](https://github.com/hendrycks/robustness) [@hendrycks_benchmarking_2019] or simulation-based approaches like the [EndlessCLSim](https://arxiv.org/abs/2106.02585) [@hess_procedural_2021], where semantically labeled street-view images are generated by a game engine, that procedurally generates the city environment and simulates drift by modifying parameters (like the weather and illumination conditions) over time.

StreamGen builds on these ideas and provides researchers with a general and intuitive framework to generate data streams without constraints on the stream characteristics and the full knowledge of underlying distributions and parameters. It will lay the foundation for more directed and efficient research on Continual Learning.

# Future work

The generation of multi-label samples requires loops and cycles for a compact and convenient representation. Such scenarios are still representable with tree data structures by unrolling these cycles through many redundant paths and transformations. A representation using less restricted types of graphs presents an interesting future extension to the framework. StreamGen already defines protocols and base classes to include different sampler concepts in the future. More declarative ways to build schedules and distributions with special characteristic represent other promising extensions.

# Acknowledgements

This work was funded by the Austrian Research Promotion Agency (FFG, Project No. 905107).

Special thanks to Benjamin Steinwender, Marius Birkenbach, Nikolaus Neugebauer, Matthew Feickert, Hoang Anh Ngo and Iztok Fister Jr. for their valuable feedback.
I also want to thank Infineon and KAI for letting me publish this project under a permissive and open license.
Finally, I want to thank my university supervisors Thomas Pock and Marc Masana for their guidance and trust in me and my visions.

# References
